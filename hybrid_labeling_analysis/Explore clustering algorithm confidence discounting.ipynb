{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "324ae94e",
   "metadata": {},
   "source": [
    "# Explore clustering algorithm confidence discounting\n",
    "The proposed clustering algorithm confidence discounting algorithm (https://github.com/e-mission/e-mission-docs/issues/663#issuecomment-898994131) has several parameters that may be tuned. This is to explore what they should be set to and whether the algorithm works well overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f855563b",
   "metadata": {},
   "source": [
    "For now, I will not do the full testing, which would consist of a train/test split, running the clustering on only the training data, then comparing the calculated p-values to how well each cluster actually does at predicting test trips."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e402ef8",
   "metadata": {},
   "source": [
    "First, let's get some users. We select only users who have at least 30 confirmed trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72e9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copypasted from Explore stage before vs after; TODO refactor into a module\n",
    "import emission.storage.timeseries.abstract_timeseries as esta\n",
    "\n",
    "EXCLUDE_UUIDS = [UUID(s) for s in input(\"Enter UUIDs to exclude, separated by spaces: \").split(\" \") if len(s) > 0]\n",
    "REQUIRED_TRIPS_TOTAL = 30\n",
    "\n",
    "def filter_update(new, old, reason):\n",
    "    print(f\"Excluded {len(old)-len(new)} users, left with {len(new)}: {reason}\")\n",
    "\n",
    "all_users = esta.TimeSeries.get_uuid_list()\n",
    "confirmed_trip_df_map = {}\n",
    "print(f\"Working with {len(all_users)} initial users\")\n",
    "\n",
    "filter0_users = [u for u in all_users if u not in EXCLUDE_UUIDS]  # Users that we don't explicitly exclude\n",
    "filter_update(filter0_users, all_users, \"presence on exclusion list\")\n",
    "\n",
    "filter1_users = []  # Users with enough total trips\n",
    "for u in filter0_users:\n",
    "    ts = esta.TimeSeries.get_time_series(u)\n",
    "    ct_df = ts.get_data_df(\"analysis/confirmed_trip\")\n",
    "    confirmed_trip_df_map[u] = ct_df\n",
    "    if ct_df.shape[0] >= REQUIRED_TRIPS_TOTAL: filter1_users.append(u)\n",
    "filter_update(filter1_users, filter0_users, \"not enough total trips\")\n",
    "\n",
    "filtered_users = filter1_users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba8e86d",
   "metadata": {},
   "source": [
    "Now let's get all the cleaned trips for those users and figure out what the naïve predictions would be. Note that this requires the model files to be copied into the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046cf7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emission.storage.decorations.analysis_timeseries_queries as esda\n",
    "import emission.analysis.classification.inference.labels.inferrers as eacili\n",
    "import arrow\n",
    "import emission.storage.timeseries.timequery as estt\n",
    "import uuid\n",
    "import emission.analysis.modelling.tour_model.data_preprocessing as preprocess\n",
    "import emission.analysis.modelling.tour_model_first_only.load_predict as lp\n",
    "\n",
    "cleaned_trips = []\n",
    "findings = []\n",
    "naive_ps = {0.0, 1.0}\n",
    "naive_counts = {}\n",
    "for u in filtered_users:\n",
    "    tq = estt.TimeQuery(\"data.end_ts\", arrow.get(\"2010-01-01\").timestamp, arrow.now().timestamp)\n",
    "    cleaned_trips += esda.get_entries(esda.CLEANED_TRIP_KEY, u, time_query=tq)\n",
    "for trip in cleaned_trips:\n",
    "    finding = {}\n",
    "    finding[\"trip\"] = trip\n",
    "    finding[\"naive_prediction\"] = eacili.predict_two_stage_bin_cluster(trip)\n",
    "    finding[\"naive_mli_p\"] = finding[\"naive_prediction\"][0][\"p\"] if len(finding[\"naive_prediction\"]) > 0 else 0\n",
    "    naive_ps.add(finding[\"naive_mli_p\"])\n",
    "    if finding[\"naive_mli_p\"] not in naive_counts: naive_counts[finding[\"naive_mli_p\"]] = 0\n",
    "    naive_counts[finding[\"naive_mli_p\"]] += 1\n",
    "    findings.append(finding)\n",
    "    \n",
    "print(len(cleaned_trips))\n",
    "print(len(findings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fcd23a",
   "metadata": {},
   "source": [
    "Now let's compute discounted predictions and test out our graphing functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c996d64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "discounted_ps = {0.0, 1.0}\n",
    "discounted_counts = {}\n",
    "def compute_discounting_full(max_confidence=None, first_confidence=None, confidence_multiplier=None):\n",
    "    global discounted_ps, discounted_counts\n",
    "    discounted_ps = {0.0, 1.0}\n",
    "    discounted_counts = {}\n",
    "    for finding in findings:\n",
    "        finding[\"discounted_prediction\"] = eacili.predict_cluster_confidence_discounting(finding[\"trip\"], max_confidence, first_confidence, confidence_multiplier)\n",
    "        finding[\"discounted_mli_p\"] = finding[\"discounted_prediction\"][0][\"p\"] if len(finding[\"discounted_prediction\"]) > 0 else 0\n",
    "        discounted_ps.add(finding[\"discounted_mli_p\"])\n",
    "        if finding[\"discounted_mli_p\"] not in discounted_counts: discounted_counts[finding[\"discounted_mli_p\"]] = 0\n",
    "        discounted_counts[finding[\"discounted_mli_p\"]] += 1\n",
    "    return discounted_ps, discounted_counts\n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "def bar(labels, a, b, title, figsize):\n",
    "    x = np.arange(len(labels))\n",
    "    y_a = [a[k] if k in a else 0 for k in labels]\n",
    "    y_b = [b[k] if k in b else 0 for k in labels]\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=figsize)\n",
    "    width = 0.4\n",
    "    bars_a = ax.bar(x-width/2, y_a, width, label=\"Naïve\")\n",
    "    bars_b = ax.bar(x+width/2, y_b, width, label=\"Discounted\")\n",
    "\n",
    "    ax.set_ylabel(\"Number of trips\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f\"{n:.2f}\" for n in labels])\n",
    "    ax.legend()\n",
    "    \n",
    "    for i,l in enumerate(ax.xaxis.get_ticklabels()):\n",
    "        if i < 6 or i >= len(labels)-6: l.set_rotation(90)\n",
    "        elif i % 4 != 0: l.set_visible(False)  # Hide labels that don't fit\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def expand_dict(src, dest):\n",
    "    for k in src: dest += [float(k)]*int(src[k])\n",
    "    \n",
    "def box(a, b, title, figsize, first_confidence):\n",
    "    data = [[] for i in range(4)]\n",
    "    labels = [\"Naïve\", \"Discounted\", \"Naïve no 0\", \"Discounted no 0\", \"Naïve no 0, 1\", \"Discounted no 0, B\"]\n",
    "    expand_dict(a, data[0])\n",
    "    expand_dict(b, data[1])\n",
    "    a_no_0 = a.copy()\n",
    "    a_no_0[0] = 0\n",
    "    b_no_0 = b.copy()\n",
    "    b_no_0[0] = 0\n",
    "    expand_dict(a_no_0, data[2])\n",
    "    expand_dict(b_no_0, data[3])\n",
    "    \n",
    "    # These are not very useful because stripping out the 1s is not the same as stripping out the Bs\n",
    "    # a_no_extremes = a_no_0.copy()\n",
    "    # a_no_extremes[1] = 0\n",
    "    # b_no_extremes = b_no_0.copy()\n",
    "    # b_no_extremes[first_confidence] = 0\n",
    "    # expand_dict(a_no_extremes, data[4])\n",
    "    # expand_dict(b_no_extremes, data[5])\n",
    "    \n",
    "    fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticklabels(labels)\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\") # https://github.com/matplotlib/matplotlib/issues/16353\n",
    "    ax.boxplot(data)\n",
    "    warnings.resetwarnings()\n",
    "    \n",
    "def viz_discounting(max_confidence, first_confidence, confidence_multiplier, bar_figsize=(20,10), box_figsize=(10,5), title_add=\"\"):\n",
    "    compute_discounting_full(max_confidence, first_confidence, confidence_multiplier)\n",
    "    print(f\"Not shown: {naive_counts[0.0]}, {discounted_counts[0.0]} trips with confidence 0\")\n",
    "    labels = list((naive_ps | discounted_ps) - {0.0})\n",
    "    labels.sort()\n",
    "    title = f\"A={1-max_confidence:.2f}, B={first_confidence:.2f}, C={confidence_multiplier:.2f}\"+title_add\n",
    "    bar(labels, naive_counts, discounted_counts, title, bar_figsize)\n",
    "    box(naive_counts, discounted_counts, title, box_figsize, first_confidence)\n",
    "    \n",
    "viz_discounting(0.99, 0.75, 0.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915331fd",
   "metadata": {},
   "source": [
    "And now let's use the graphs to test out a bunch of scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9485d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = {\n",
    "    \"default\": (0.99, 0.75, 0.25),\n",
    "    \"no_a\": (1.00, 0.75, 0.25),\n",
    "    \"high_a\": (0.95, 0.75, 0.25),\n",
    "    \"higher_a\": (0.90, 0.75, 0.25),\n",
    "    \"low_b\": (0.99, 0.6, 0.25),\n",
    "    \"lower_b\": (0.99, 0.3, 0.25),\n",
    "    \"low_c\": (0.99, 0.5, 0.10),\n",
    "    \"low_b_and_c\": (0.99, 0.6, 0.10)\n",
    "}\n",
    "\n",
    "for scenario in scenarios:\n",
    "    viz_discounting(*scenarios[scenario], title_add=f\" ({scenario})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf05edc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
